# ECHO: Emotion Classification from Hybrid Operations

ECHO (Emotion Classification from Hybrid Operations) is a robust deep learning project aimed at classifying emotions in speech. This project showcases the development of multiple models, each leveraging unique architectures and methodologies to achieve high accuracy in emotion detection.

## Overview

The primary objective of ECHO is to analyze speech data and classify emotions into predefined categories. By employing different neural network architectures, the project illustrates the effectiveness of combining various models to enhance performance.

## Models Developed

### 1. Convolutional Neural Network (CNN)

The CNN model focuses on feature extraction from the audio spectrograms. It effectively identifies spatial hierarchies in the data, leading to improved classification accuracy.

![CNN Architecture](https://github.com/nathsujal/ECHO/blob/main/model-architecture-visuals/cnn-architecture.svg)

### 2. Long Short-Term Memory (LSTM) Network

The LSTM model is designed to capture temporal dependencies in the speech data. It is particularly effective for sequences, making it well-suited for emotion detection in audio.

![LSTM Architecture](https://github.com/nathsujal/ECHO/blob/main/model-architecture-visuals/lstm-architecture.svg)

### 3. Hybrid Model

The hybrid model combines both CNN and LSTM architectures, leveraging the strengths of each to provide superior emotion classification. This approach enhances the model's ability to process complex patterns in speech data.

![Hybrid Model Architecture](https://github.com/nathsujal/ECHO/blob/main/model-architecture-visuals/cnn-lstm-architecture.svg)
